networks:
  openim:
    driver: bridge

services:
  mongo:
    image: "${MONGO_IMAGE}"
    container_name: mongo
    ports:
      - "27017:27017"  # 映射到主机端口
    command: >
      bash -c '
      docker-entrypoint.sh mongod --wiredTigerCacheSizeGB $$wiredTigerCacheSizeGB --auth &
      until mongosh -u $$MONGO_INITDB_ROOT_USERNAME -p $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval "db.runCommand({ ping: 1 })" &>/dev/null; do
        echo "Waiting for MongoDB to start..."
        sleep 1
      done &&
      mongosh -u $$MONGO_INITDB_ROOT_USERNAME -p $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval "
      db = db.getSiblingDB(\"$$MONGO_INITDB_DATABASE\");
      if (!db.getUser(\"$$MONGO_OPENIM_USERNAME\")) {
        db.createUser({
          user: \"$$MONGO_OPENIM_USERNAME\",
          pwd: \"$$MONGO_OPENIM_PASSWORD\",
          roles: [{role: \"readWrite\", db: \"$$MONGO_INITDB_DATABASE\"}]
        });
        print(\"User created successfully: \");
        print(\"Username: $$MONGO_OPENIM_USERNAME\");
        print(\"Password: $$MONGO_OPENIM_PASSWORD\");
        print(\"Database: $$MONGO_INITDB_DATABASE\");
      } else {
        print(\"User already exists in database: $$MONGO_INITDB_DATABASE, Username: $$MONGO_OPENIM_USERNAME\");
      }
      " &&
      tail -f /dev/null
      '
    volumes:
      - "${DATA_DIR}/components/mongodb/data/db:/data/db"
      - "${DATA_DIR}/components/mongodb/data/logs:/data/logs"
      - "${DATA_DIR}/components/mongodb/data/conf:/etc/mongo"
    environment:
      - TZ=Asia/Shanghai
      - wiredTigerCacheSizeGB=1
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=openIM123
      - MONGO_INITDB_DATABASE=openim_v3
      - MONGO_OPENIM_USERNAME=${MONGO_USERNAME}
      - MONGO_OPENIM_PASSWORD=${MONGO_PASSWORD}
    restart: always
    networks:
      - openim

  redis:
    image: "${REDIS_IMAGE}"
    container_name: redis
    ports:
      - "16379:6379"  # 映射到主机端口 16379
    volumes:
      - "${DATA_DIR}/components/redis/data:/data"
      - "${DATA_DIR}/components/redis/config/redis.conf:/usr/local/redis/config/redis.conf"
    environment:
      TZ: Asia/Shanghai
    restart: always
    sysctls:
      net.core.somaxconn: 1024
    command:
      [
        "redis-server",
        "/usr/local/redis/config/redis.conf",
        "--requirepass",
        "${REDIS_PASSWORD}",
        "--appendonly",
        "yes",
      ]
    networks:
      - openim

  etcd:
    image: "${ETCD_IMAGE}"
    container_name: etcd
    ports:
      - "12379:2379"
      - "12380:2380"
    environment:
      - ETCD_NAME=s1
      - ETCD_DATA_DIR=/etcd-data
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_LISTEN_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_ADVERTISE_PEER_URLS=http://0.0.0.0:2380
      - ETCD_INITIAL_CLUSTER=s1=http://0.0.0.0:2380
      - ETCD_INITIAL_CLUSTER_TOKEN=tkn
      - ETCD_INITIAL_CLUSTER_STATE=new
      - ALLOW_NONE_AUTHENTICATION=no

      ## Optional: Enable etcd authentication by setting the following credentials
      # - ETCD_ROOT_USER=root
      # - ETCD_ROOT_PASSWORD=openIM123
      # - ETCD_USERNAME=openIM
      # - ETCD_PASSWORD=openIM123
    volumes:
      - "${DATA_DIR}/components/etcd:/etcd-data"
    command: >
      /bin/sh -c '
        etcd &
        export ETCDCTL_API=3
        echo "Waiting for etcd to become healthy..."
        until etcdctl --endpoints=http://127.0.0.1:2379 endpoint health &>/dev/null; do
          echo "Waiting for ETCD to start..."
          sleep 1
        done

        echo "etcd is healthy."

        if [ -n "$${ETCD_ROOT_USER}" ] && [ -n "$${ETCD_ROOT_PASSWORD}" ] && [ -n "$${ETCD_USERNAME}" ] && [ -n "$${ETCD_PASSWORD}" ]; then
          echo "Authentication credentials provided. Setting up authentication..."

        echo "Checking authentication status..."
        if ! etcdctl --endpoints=http://127.0.0.1:2379 auth status | grep -q "Authentication Status: true"; then
          echo "Authentication is disabled. Creating users and enabling..."
          
          # Create users and setup permissions
          etcdctl --endpoints=http://127.0.0.1:2379 user add $${ETCD_ROOT_USER} --new-user-password=$${ETCD_ROOT_PASSWORD} || true
          etcdctl --endpoints=http://127.0.0.1:2379 user add $${ETCD_USERNAME} --new-user-password=$${ETCD_PASSWORD} || true
          
          etcdctl --endpoints=http://127.0.0.1:2379 role add openim-role || true
          etcdctl --endpoints=http://127.0.0.1:2379 role grant-permission openim-role --prefix=true readwrite / || true
          etcdctl --endpoints=http://127.0.0.1:2379 role grant-permission openim-role --prefix=true readwrite "" || true
          etcdctl --endpoints=http://127.0.0.1:2379 user grant-role $${ETCD_USERNAME} openim-role || true
          
          etcdctl --endpoints=http://127.0.0.1:2379 user grant-role $${ETCD_ROOT_USER} $${ETCD_USERNAME} root || true
          
          echo "Enabling authentication..."
          etcdctl --endpoints=http://127.0.0.1:2379 auth enable
          echo "Authentication enabled successfully"
        else
          echo "Authentication is already enabled. Checking OpenIM user..."
          
          # Check if openIM user exists and can perform operations
          if ! etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_USERNAME}:$${ETCD_PASSWORD} put /test/auth "auth-check" &>/dev/null; then
            echo "OpenIM user test failed. Recreating user with root credentials..."
            
            # Try to create/update the openIM user using root credentials
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_ROOT_USER}:$${ETCD_ROOT_PASSWORD} user add $${ETCD_USERNAME} --new-user-password=$${ETCD_PASSWORD} --no-password-file || true
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_ROOT_USER}:$${ETCD_ROOT_PASSWORD} role add openim-role || true
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_ROOT_USER}:$${ETCD_ROOT_PASSWORD} role grant-permission openim-role --prefix=true readwrite / || true
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_ROOT_USER}:$${ETCD_ROOT_PASSWORD} role grant-permission openim-role --prefix=true readwrite "" || true
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_ROOT_USER}:$${ETCD_ROOT_PASSWORD} user grant-role $${ETCD_USERNAME} openim-role || true
            etcdctl --endpoints=http://127.0.0.1:2379 user grant-role $${ETCD_ROOT_USER} $${ETCD_USERNAME} root || true
            
            echo "OpenIM user recreated with required permissions"
          else
            echo "OpenIM user exists and has correct permissions"
            etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_USERNAME}:$${ETCD_PASSWORD} del /test/auth &>/dev/null
          fi
        fi
        echo "Testing authentication with OpenIM user..."
        if etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_USERNAME}:$${ETCD_PASSWORD} put /test/auth "auth-works"; then
          echo "Authentication working properly"
          etcdctl --endpoints=http://127.0.0.1:2379 --user=$${ETCD_USERNAME}:$${ETCD_PASSWORD} del /test/auth
        else
          echo "WARNING: Authentication test failed"
          fi
        else
          echo "No authentication credentials provided. Running in no-auth mode."
          echo "To enable authentication, set ETCD_ROOT_USER, ETCD_ROOT_PASSWORD, ETCD_USERNAME, and ETCD_PASSWORD environment variables."
        fi
        
        tail -f /dev/null
      '
    restart: always
    networks:
      - openim

  kafka:
    image: "${KAFKA_IMAGE}"
    container_name: kafka
    user: root
    restart: always
    ports:
      - "19094:9094"  # 映射 EXTERNAL 监听器到主机端口 19094
    volumes:
      - "${DATA_DIR}/components/kafka:/bitnami/kafka"
    environment:
      #KAFKA_HEAP_OPTS: "-Xms128m -Xmx256m"
      TZ: Asia/Shanghai
      # Unique identifier for the Kafka node (required in controller mode)
      KAFKA_CFG_NODE_ID: 0
      # Defines the roles this Kafka node plays: broker, controller, or both
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      # Specifies which nodes are controller nodes for quorum voting.
      # The syntax follows the KRaft mode (no ZooKeeper): node.id@host:port
      # The controller listener endpoint here is kafka:9093
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 0@kafka:9093
      # Specifies which listener is used for controller-to-controller communication
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      # Default number of partitions for new topics
      KAFKA_NUM_PARTITIONS: 8
      # Whether to enable automatic topic creation
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Kafka internal listeners; Kafka supports multiple ports with different protocols
      # Each port is used for a specific purpose: INTERNAL for internal broker communication,
      # CONTROLLER for controller communication, EXTERNAL for external client connections.
      # These logical listener names are mapped to actual protocols via KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
      # In short, Kafka is listening on three logical ports: 9092 for internal communication,
      # 9093 for controller traffic, and 9094 for external access.
      # Kafka listeners configuration
      # When KAFKA_USERNAME is set, SASL authentication is enabled
      # Use SASL_PLAINTEXT for listeners when authentication is enabled
      KAFKA_CFG_LISTENERS: "SASL_PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094"
      # Addresses advertised to clients. INTERNAL://kafka:9092 uses the internal Docker service name 'kafka',
      # so other containers can access Kafka via kafka:9092.
      # EXTERNAL://kafka:9094 is the address for container-internal clients to connect.
      # For external clients on the host machine, use 127.0.0.1:19094 (mapped from container port 9094).
      KAFKA_CFG_ADVERTISED_LISTENERS: "SASL_PLAINTEXT://kafka:9092,EXTERNAL://kafka:9094"
      # Maps logical listener names to actual protocols.
      # EXTERNAL listener uses SASL_PLAINTEXT when authentication is enabled
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT,SASL_PLAINTEXT:SASL_PLAINTEXT"
      # Defines which listener is used for inter-broker communication within the Kafka cluster
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: "SASL_PLAINTEXT"

      # Authentication configuration variables
      KAFKA_USERNAME: ${KAFKA_USERNAME:-}
      KAFKA_PASSWORD: ${KAFKA_PASSWORD:-}
      # SASL configuration
      KAFKA_CFG_SASL_ENABLED_MECHANISMS: "PLAIN"
      KAFKA_CFG_SASL_MECHANISM_INTER_BROKER_PROTOCOL: "PLAIN"
      KAFKA_CLIENT_USERS: ${KAFKA_USERNAME:-}
      KAFKA_CLIENT_PASSWORDS: ${KAFKA_PASSWORD:-}
    networks:
      - openim

  minio:
    image: "${MINIO_IMAGE}"
    ports:
      - "${MINIO_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9090"
    container_name: minio
    volumes:
      - "${DATA_DIR}/components/mnt/data:/data"
      - "${DATA_DIR}/components/mnt/config:/root/.minio"
    environment:
      TZ: Asia/Shanghai
      MINIO_ROOT_USER: "${MINIO_ACCESS_KEY_ID}"
      MINIO_ROOT_PASSWORD: "${MINIO_SECRET_ACCESS_KEY}"
    restart: always
    command: minio server /data --console-address ':9090'
    networks:
      - openim

  openim-web-front:
    image: ${OPENIM_WEB_FRONT_IMAGE}
    container_name: openim-web-front
    restart: always
    ports:
      - "${OPENIM_WEB_FRONT_PORT}:80"
    networks:
      - openim

  # openim-admin-front:
  #   image: ${OPENIM_ADMIN_FRONT_IMAGE}
  #   container_name: openim-admin-front
  #   restart: always
  #   ports:
  #     - "${OPENIM_ADMIN_FRONT_PORT}:80"
  #   networks:
  #     - openim

  prometheus:
    image: ${PROMETHEUS_IMAGE}
    container_name: prometheus
    restart: always
    user: root
    profiles:
      - m
    ports:
      - "${PROMETHEUS_PORT}:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./config/instance-down-rules.yml:/etc/prometheus/instance-down-rules.yml
      - ${DATA_DIR}/components/prometheus/data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.listen-address=:9090"
    networks:
      - openim

  alertmanager:
    image: ${ALERTMANAGER_IMAGE}
    container_name: alertmanager
    restart: always
    profiles:
      - m
    ports:
      - "${ALERTMANAGER_PORT}:9093"
    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./config/email.tmpl:/etc/alertmanager/email.tmpl
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--web.listen-address=:9093"
    networks:
      - openim

  grafana:
    image: ${GRAFANA_IMAGE}
    container_name: grafana
    user: root
    restart: always
    profiles:
      - m
    ports:
      - "${GRAFANA_PORT}:3000"
    environment:
      - GF_SECURITY_ALLOW_EMBEDDING=true
      - GF_SESSION_COOKIE_SAMESITE=none
      - GF_SESSION_COOKIE_SECURE=true
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_SERVER_HTTP_PORT=3000
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ${DATA_DIR:-./}/components/grafana:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - openim

  loki:
    image: ${LOKI_IMAGE}
    container_name: loki
    user: root
    restart: always
    profiles:
      - m
    ports:
      - "${LOKI_PORT}:3100"
    volumes:
      - ./config/loki-config.yaml:/etc/loki/local-config.yaml
      - ${DATA_DIR}/components/loki:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - openim

  jaeger:
    image: ${JAEGER_IMAGE}
    container_name: jaeger
    restart: always
    profiles:
      - m
    ports:
      - "${JAEGER_UI_PORT}:16686"
      - "4317:4317"
      - "4318:4318"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - openim

  promtail:
    image: ${PROMTAIL_IMAGE}
    container_name: promtail
    restart: always
    profiles:
      - m
    volumes:
      - ./config/promtail-config.yaml:/etc/promtail/config.yaml
      # LOG_COLLECT_DIR: 宿主机含 rust.log* 的目录；未设置时用项目内 ./rust-logs
      - ${LOG_COLLECT_DIR:-./rust-logs}:/logs:ro
      - ${DATA_DIR}/components/openim-logs:/openim-logs:ro
      - ${DATA_DIR}/components/promtail/positions:/tmp
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yaml
    networks:
      - openim

  openim-server:
    image: ${OPENIM_SERVER_IMAGE}
    container_name: openim-server
    init: true
    ports:
      - "${OPENIM_MSG_GATEWAY_PORT}:10001"
      - "${OPENIM_API_PORT}:10002"
    healthcheck:
      test: ["CMD", "sh", "-c", "mage check"]
      interval: 5s
      timeout: 60s
      retries: 10
    environment:
      - IMENV_MONGODB_ADDRESS=${MONGO_ADDRESS}
      - IMENV_MONGODB_USERNAME=${MONGO_USERNAME}
      - IMENV_MONGODB_PASSWORD=${MONGO_PASSWORD}
      - IMENV_KAFKA_ADDRESS=${KAFKA_ADDRESS}
      - IMENV_KAFKA_USERNAME=${KAFKA_USERNAME}
      - IMENV_KAFKA_PASSWORD=${KAFKA_PASSWORD}
      - IMENV_DISCOVERY_ETCD_ADDRESS=${ETCD_ADDRESS}
      - IMENV_REDIS_ADDRESS=${REDIS_ADDRESS}
      - IMENV_REDIS_PASSWORD=${REDIS_PASSWORD}
      - IMENV_DISCOVERY_ETCD_USERNAME=${ETCD_USERNAME}
      - IMENV_DISCOVERY_ETCD_PASSWORD=${ETCD_PASSWORD}
      - IMENV_MINIO_INTERNALADDRESS=${MINIO_INTERNAL_ADDRESS}
      - IMENV_MINIO_EXTERNALADDRESS=${MINIO_EXTERNAL_ADDRESS}
      - IMENV_MINIO_ACCESSKEYID=${MINIO_ACCESS_KEY_ID}
      - IMENV_MINIO_SECRETACCESSKEY=${MINIO_SECRET_ACCESS_KEY}
      - IMENV_SHARE_SECRET=${OPENIM_SECRET}
      - IMENV_LOG_ISSTDOUT=${LOG_IS_STDOUT}
      - IMENV_LOG_REMAINLOGLEVEL=${LOG_LEVEL}
      - IMENV_LOG_STORAGEDIR=/var/log/openim
      - IMENV_OPENIM_API_PROMETHEUS_GRAFANAURL=${GRAFANA_URL}
    volumes:
      - ${DATA_DIR}/components/openim-logs/server:/var/log/openim
    restart: always
    depends_on:
      - mongo
      - redis
      - etcd
      - kafka
      - minio
    networks:
      - openim

  openim-chat:
    image: ${OPENIM_CHAT_IMAGE}
    container_name: openim-chat
    init: true
    healthcheck:
      test: ["CMD", "sh", "-c", "mage check"]
      interval: 5s
      timeout: 60s
      retries: 10
    environment:
      - CHATENV_MONGODB_ADDRESS=${MONGO_ADDRESS}
      - CHATENV_MONGODB_USERNAME=${MONGO_USERNAME}
      - CHATENV_MONGODB_PASSWORD=${MONGO_PASSWORD}
      - CHATENV_DISCOVERY_ETCD_ADDRESS=${ETCD_ADDRESS}
      - CHATENV_REDIS_ADDRESS=${REDIS_ADDRESS}
      - CHATENV_REDIS_PASSWORD=${REDIS_PASSWORD}
      - CHATENV_SHARE_OPENIM_SECRET=${OPENIM_SECRET}
      - CHATENV_DISCOVERY_ETCD_USERNAME=${ETCD_USERNAME}
      - CHATENV_DISCOVERY_ETCD_PASSWORD=${ETCD_PASSWORD}
      - CHATENV_SHARE_OPENIM_APIURL=${API_URL}
      - CHATENV_LOG_ISSTDOUT=${LOG_IS_STDOUT}
      - CHATENV_LOG_REMAINLOGLEVEL=${LOG_LEVEL}
      - CHATENV_LOG_STORAGEDIR=/var/log/openim
    volumes:
      - ${DATA_DIR}/components/openim-logs/chat:/var/log/openim
    ports:
      - "${CHAT_API_PORT}:10008"
      - "${ADMIN_API_PORT}:10009"
    restart: always
    depends_on:
      - mongo
      - redis
      - etcd
      - kafka
      - minio
      - openim-server
    networks:
      - openim
